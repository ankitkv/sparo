# SPARO: Selective Attention for Robust and Compositional Transformer Encodings for Vision

This code is based on [OpenCLIP v2.20.0](https://github.com/mlfoundations/open_clip/tree/v2.20.0), and illustrates incorporation of SPARO onto the CLIP encoders.

The paper will be available on arXiv soon.

Demo scripts for training models on a single GPU are provided in `scripts/`.
